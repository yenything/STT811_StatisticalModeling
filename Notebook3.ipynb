{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK 3 \n",
    "\n",
    "**TEAM MEMBERS :-** <br/>\n",
    "**1. Lacey Hamilton**<br/>\n",
    "**2. Megha Viswanath**<br/>\n",
    "**3. Yena Hong**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHY WORK ON A SAMPLE ?\n",
    "\n",
    "**To gain a better understanding of the features and determine the most effective feature engineering approach, we initially performed our modeling and analysis using a subset of the dataset, selecting only one CSV file from each malware family instead of using all the provided CSVs. This strategy allowed us to efficiently explore the relationships between features, evaluate different feature engineering techniques, and refine our models in a more manageable and focused manner, ultimately enhancing the performance of our final Android malware detection model.**\n",
    "\n",
    "\n",
    "### Same code is applied for the Multiclass Classifier Notebook 4 with some added improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All Library imports for the entire project given here\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all datasets \n",
    "# Get all CSV files in the current directory\n",
    "csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "\n",
    "# Combine all CSV files into a single DataFrame\n",
    "df = pd.concat((pd.read_csv(f) for f in csv_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.42.0.151-104.46.62.41-58063-443-6</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>58063</td>\n",
       "      <td>104.46.62.41</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>13-06-2017 05:22</td>\n",
       "      <td>209484</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.42.0.151-104.46.62.41-58063-443-6</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>58063</td>\n",
       "      <td>104.46.62.41</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>13-06-2017 05:22</td>\n",
       "      <td>31308</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Flow ID    Source IP   Source Port  \\\n",
       "0  10.42.0.151-104.46.62.41-58063-443-6  10.42.0.151         58063   \n",
       "1  10.42.0.151-104.46.62.41-58063-443-6  10.42.0.151         58063   \n",
       "\n",
       "   Destination IP   Destination Port   Protocol         Timestamp  \\\n",
       "0    104.46.62.41                443          6  13-06-2017 05:22   \n",
       "1    104.46.62.41                443          6  13-06-2017 05:22   \n",
       "\n",
       "    Flow Duration   Total Fwd Packets   Total Backward Packets  ...  \\\n",
       "0          209484                   1                        2  ...   \n",
       "1           31308                   2                        0  ...   \n",
       "\n",
       "    min_seg_size_forward  Active Mean   Active Std   Active Max   Active Min  \\\n",
       "0                     32          0.0          0.0          0.0          0.0   \n",
       "1                     32          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
       "0        0.0        0.0        0.0        0.0  ADWARE  \n",
       "1        0.0        0.0        0.0        0.0  ADWARE  \n",
       "\n",
       "[2 rows x 85 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11368, 85)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11368, 85)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values in both the columns are same.\n"
     ]
    }
   ],
   "source": [
    "#Check if the number of same values between teh two columns equals the number of rows in the dataframe\n",
    "if df.shape[0] == len(np.where(df.iloc[:, 40] == df.iloc[:, 61])[0]):\n",
    "    print(\"The values in both the columns are same.\")\n",
    "    df = df.drop(df.columns[61], axis=1)\n",
    "    #print(\"Duplicate column thus dropped.\")\n",
    "else:\n",
    "    print(\"The values do not match. Hence we can not assume both the columns have same values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow_ID', 'Source_IP', 'Destination_IP', 'Timestamp', 'Label'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(exclude='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Flow_ID\", axis=1)\n",
    "df = df.drop(\"Source_IP\", axis=1)\n",
    "df = df.drop(\"Destination_IP\", axis=1)\n",
    "df = df.drop(\"Timestamp\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataset is stored in a Pandas DataFrame called 'data'\n",
    "# Create new features by calculating ratios\n",
    "data = df\n",
    "data['Fwd_Bwd_Packet_Length_Mean_Ratio'] = data['Fwd_Packet_Length_Mean'] / data['Bwd_Packet_Length_Mean']\n",
    "data['Fwd_Bwd_Packets_per_s_Ratio'] = data['Fwd_Packets/s'] / data['Bwd_Packets/s']\n",
    "data['Fwd_Bwd_Header_Length_Ratio'] = data['Fwd_Header_Length'] / data['Bwd_Header_Length']\n",
    "data['Fwd_Bwd_IAT_Mean_Ratio'] = data['Fwd_IAT_Mean'] / data['Bwd_IAT_Mean']\n",
    "data['Flow_Bytes_Packets_per_s_Ratio'] = data['Flow_Bytes/s'] / data['Flow_Packets/s']\n",
    "data['Avg_Fwd_Bwd_Segment_Size_Ratio'] = data['Avg_Fwd_Segment_Size'] / data['Avg_Bwd_Segment_Size']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated features\n",
    "data['Total_Packets'] = data['Total_Fwd_Packets'] + data['Total_Backward_Packets']\n",
    "data['Total_Bytes'] = data['Total_Length_of_Fwd_Packets'] + data['Total_Length_of_Bwd_Packets']\n",
    "data['Avg_Packet_Length'] = (data['Fwd_Packet_Length_Mean'] + data['Bwd_Packet_Length_Mean']) / 2\n",
    "data['Total_IAT'] = data['Fwd_IAT_Total'] + data['Bwd_IAT_Total']\n",
    "data['Total_Header_Length'] = data['Fwd_Header_Length'] + data['Bwd_Header_Length']\n",
    "\n",
    "# Interaction features\n",
    "data['Fwd_Bwd_Packet_Length_Mean_Diff'] = data['Fwd_Packet_Length_Mean'] - data['Bwd_Packet_Length_Mean']\n",
    "data['Fwd_Bwd_Packet_Length_Mean_Product'] = data['Fwd_Packet_Length_Mean'] * data['Bwd_Packet_Length_Mean']\n",
    "data['Fwd_Bwd_IAT_Mean_Diff'] = data['Fwd_IAT_Mean'] - data['Bwd_IAT_Mean']\n",
    "data['Fwd_Bwd_IAT_Mean_Product'] = data['Fwd_IAT_Mean'] * data['Bwd_IAT_Mean']\n",
    "\n",
    "# Statistical features\n",
    "packet_length_features = ['Fwd_Packet_Length_Max', 'Fwd_Packet_Length_Min', 'Fwd_Packet_Length_Mean',\n",
    "                          'Fwd_Packet_Length_Std', 'Bwd_Packet_Length_Max', 'Bwd_Packet_Length_Min',\n",
    "                          'Bwd_Packet_Length_Mean', 'Bwd_Packet_Length_Std']\n",
    "\n",
    "data['Packet_Length_Mean'] = data[packet_length_features].mean(axis=1)\n",
    "data['Packet_Length_Median'] = data[packet_length_features].median(axis=1)\n",
    "data['Packet_Length_Std'] = data[packet_length_features].std(axis=1)\n",
    "data['Packet_Length_Range'] = data[packet_length_features].max(axis=1) - data[packet_length_features].min(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the categorical variables: Protocol and Label\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# One-hot encoding for the 'Protocol' column\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "protocol_one_hot = one_hot_encoder.fit_transform(data['Protocol'].values.reshape(-1, 1))\n",
    "\n",
    "# Create new column names for the one-hot encoded 'Protocol' features\n",
    "protocol_columns = ['Protocol_' + str(i) for i in range(protocol_one_hot.shape[1])]\n",
    "\n",
    "# Add the one-hot encoded 'Protocol' features to the DataFrame and drop the original column\n",
    "data[protocol_columns] = pd.DataFrame(protocol_one_hot, index=data.index)\n",
    "data = data.drop('Protocol', axis=1)\n",
    "\n",
    "# Label encoding for the 'Label' column (target variable)\n",
    "label_encoder = LabelEncoder()\n",
    "data['Label'] = label_encoder.fit_transform(data['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value percentages:\n",
      " Fwd_Bwd_IAT_Mean_Ratio              0.602657\n",
      "Avg_Fwd_Bwd_Segment_Size_Ratio      0.499912\n",
      "Fwd_Bwd_Packet_Length_Mean_Ratio    0.499912\n",
      "Fwd_Bwd_Header_Length_Ratio         0.308058\n",
      "Fwd_Bwd_Packets_per_s_Ratio         0.307618\n",
      "                                      ...   \n",
      "Subflow_Fwd_Bytes                   0.000000\n",
      "Subflow_Bwd_Packets                 0.000000\n",
      "Subflow_Bwd_Bytes                   0.000000\n",
      "Init_Win_bytes_forward              0.000000\n",
      "Source_Port                         0.000000\n",
      "Length: 98, dtype: float64\n",
      "Feature coefficients (LASSO):\n",
      "Protocol_1: 0.23129489862524058\n",
      "min_seg_size_forward: -0.21495615533169332\n",
      "FIN_Flag_Count: -0.12914669701213655\n",
      "Packet_Length_Std: -0.1252223275532595\n",
      "Bwd_Packet_Length_Max: -0.10548986530830447\n",
      "Flow_Bytes_Packets_per_s_Ratio: 0.10434929680346951\n",
      "URG_Flag_Count: -0.09051037266251083\n",
      "Flow_IAT_Mean: -0.07810852199074796\n",
      "Fwd_PSH_Flags: -0.05443746777880298\n",
      "Bwd_Packets/s: -0.05299150538152009\n",
      "Init_Win_bytes_forward: 0.05104519664136833\n",
      "Source_Port: 0.050368991958809645\n",
      "Fwd_Packet_Length_Min: 0.0482348778448363\n",
      "Fwd_IAT_Std: -0.04631007712363631\n",
      "Fwd_Packets/s: 0.041815924054216504\n",
      "Fwd_Packet_Length_Std: 0.03787443605221279\n",
      "Min_Packet_Length: -0.035616775956428155\n",
      "Flow_IAT_Std: -0.03459452789542003\n",
      "Active_Max: 0.03197684290484062\n",
      "Bwd_IAT_Min: -0.029706755906384164\n",
      "Bwd_Packet_Length_Min: 0.022120765640903966\n",
      "Fwd_Bwd_IAT_Mean_Product: 0.020945318932499613\n",
      "Init_Win_bytes_backward: 0.02051973570256995\n",
      "SYN_Flag_Count: -0.015250854523688444\n",
      "Fwd_Bwd_Packet_Length_Mean_Product: 0.015019540507323147\n",
      "Destination_Port: -0.010393782360968997\n",
      "Total_IAT: 0.008896258646922317\n",
      "act_data_pkt_fwd: -0.008645187909193271\n",
      "Total_Length_of_Fwd_Packets: -0.006945937026024422\n",
      "Flow_IAT_Max: -0.006244030086162579\n",
      "Active_Std: 0.005349646161465543\n",
      "Fwd_Bwd_IAT_Mean_Ratio: -0.004426305214173861\n",
      "Fwd_Header_Length: -0.003012898923444751\n",
      "Subflow_Fwd_Bytes: -0.0025472888987313606\n",
      "Protocol_0: -0.001514988821677081\n",
      "Flow_Duration: -0.0\n",
      "Total_Fwd_Packets: -0.0\n",
      "Total_Backward_Packets: 0.0\n",
      "Total_Length_of_Bwd_Packets: 0.0\n",
      "Fwd_Packet_Length_Max: -0.0\n",
      "Fwd_Packet_Length_Mean: 0.0\n",
      "Bwd_Packet_Length_Mean: -0.0\n",
      "Bwd_Packet_Length_Std: -0.0\n",
      "Flow_Bytes/s: 0.0\n",
      "Flow_Packets/s: 0.0\n",
      "Flow_IAT_Min: -0.0\n",
      "Fwd_IAT_Total: 0.0\n",
      "Fwd_IAT_Mean: -0.0\n",
      "Fwd_IAT_Max: -0.0\n",
      "Fwd_IAT_Min: -0.0\n",
      "Bwd_IAT_Total: 0.0\n",
      "Bwd_IAT_Mean: -0.0\n",
      "Bwd_IAT_Std: -0.0\n",
      "Bwd_IAT_Max: -0.0\n",
      "Bwd_PSH_Flags: 0.0\n",
      "Fwd_URG_Flags: 0.0\n",
      "Bwd_URG_Flags: 0.0\n",
      "Bwd_Header_Length: 0.0\n",
      "Max_Packet_Length: -0.0\n",
      "Packet_Length_Mean: -0.0\n",
      "Packet_Length_Variance: -0.0\n",
      "RST_Flag_Count: 0.0\n",
      "PSH_Flag_Count: 0.0\n",
      "ACK_Flag_Count: 0.0\n",
      "CWE_Flag_Count: 0.0\n",
      "ECE_Flag_Count: 0.0\n",
      "Down/Up_Ratio: 0.0\n",
      "Average_Packet_Size: 0.0\n",
      "Avg_Fwd_Segment_Size: 0.0\n",
      "Avg_Bwd_Segment_Size: -0.0\n",
      "Fwd_Avg_Bytes/Bulk: 0.0\n",
      "Fwd_Avg_Packets/Bulk: 0.0\n",
      "Fwd_Avg_Bulk_Rate: 0.0\n",
      "Bwd_Avg_Bytes/Bulk: 0.0\n",
      "Bwd_Avg_Packets/Bulk: 0.0\n",
      "Bwd_Avg_Bulk_Rate: 0.0\n",
      "Subflow_Fwd_Packets: -0.0\n",
      "Subflow_Bwd_Packets: 0.0\n",
      "Subflow_Bwd_Bytes: 0.0\n",
      "Active_Mean: 0.0\n",
      "Active_Min: 0.0\n",
      "Idle_Mean: -0.0\n",
      "Idle_Std: 0.0\n",
      "Idle_Max: 0.0\n",
      "Idle_Min: -0.0\n",
      "Fwd_Bwd_Packet_Length_Mean_Ratio: 0.0\n",
      "Fwd_Bwd_Packets_per_s_Ratio: 0.0\n",
      "Fwd_Bwd_Header_Length_Ratio: 0.0\n",
      "Avg_Fwd_Bwd_Segment_Size_Ratio: 0.0\n",
      "Total_Packets: 0.0\n",
      "Total_Bytes: 0.0\n",
      "Avg_Packet_Length: -0.0\n",
      "Total_Header_Length: -0.0\n",
      "Fwd_Bwd_Packet_Length_Mean_Diff: 0.0\n",
      "Fwd_Bwd_IAT_Mean_Diff: -0.0\n",
      "Packet_Length_Median: 0.0\n",
      "Packet_Length_Range: -0.0\n",
      "Protocol_2: -0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Label', axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Check the percentage of missing values in each column\n",
    "missing_percentages = X.isna().mean().sort_values(ascending=False)\n",
    "print(\"Missing value percentages:\\n\", missing_percentages)\n",
    "\n",
    "# Impute missing values using mean, median, or a constant value\n",
    "# You can choose an appropriate strategy based on your data\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# LASSO model for feature importance\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Pair feature names with their coefficients\n",
    "feature_coefficient_pairs = list(zip(X.columns, lasso_importances))\n",
    "\n",
    "# Sort the feature coefficient pairs by absolute coefficient value (descending order)\n",
    "sorted_feature_coefficient_pairs = sorted(feature_coefficient_pairs, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print the sorted feature coefficient pairs\n",
    "print(\"Feature coefficients (LASSO):\")\n",
    "for feature, coefficient in sorted_feature_coefficient_pairs:\n",
    "    print(f\"{feature}: {coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances (Random Forest):\n",
      "Source_Port: 0.05267238990400279\n",
      "Flow_Duration: 0.04081082960740954\n",
      "Flow_IAT_Max: 0.039271399895039874\n",
      "Flow_IAT_Min: 0.039124293290823016\n",
      "Flow_IAT_Mean: 0.037536511670189815\n",
      "Init_Win_bytes_forward: 0.03685480406148481\n",
      "Fwd_Packets/s: 0.03598903236403668\n",
      "Flow_Packets/s: 0.03553883420169848\n",
      "Fwd_IAT_Min: 0.03231410572370882\n",
      "Fwd_Bwd_IAT_Mean_Diff: 0.027967505005339552\n",
      "Fwd_IAT_Mean: 0.02686560303086267\n",
      "Fwd_IAT_Max: 0.026513242483825902\n",
      "Total_IAT: 0.026420069190839154\n",
      "Fwd_IAT_Total: 0.026344271022269834\n",
      "Destination_Port: 0.02460041928292783\n",
      "Bwd_Packets/s: 0.02340695198231803\n",
      "Init_Win_bytes_backward: 0.01817452790215907\n",
      "Total_Header_Length: 0.015315144957373938\n",
      "Flow_Bytes/s: 0.015213608049957956\n",
      "Flow_IAT_Std: 0.015167267410301263\n",
      "Fwd_IAT_Std: 0.014159714624352664\n",
      "Fwd_Bwd_Header_Length_Ratio: 0.01327302862868136\n",
      "Fwd_Header_Length: 0.012566247696052706\n",
      "Fwd_Bwd_Packets_per_s_Ratio: 0.010899833467612887\n",
      "min_seg_size_forward: 0.010792969231798018\n",
      "Avg_Fwd_Segment_Size: 0.00957145742826135\n",
      "Flow_Bytes_Packets_per_s_Ratio: 0.009512853415953277\n",
      "Average_Packet_Size: 0.009378237143983828\n",
      "Fwd_Bwd_Packet_Length_Mean_Ratio: 0.008967544068095667\n",
      "Fwd_Packet_Length_Mean: 0.008965281987837396\n",
      "Avg_Fwd_Bwd_Segment_Size_Ratio: 0.008920687488406036\n",
      "Subflow_Fwd_Bytes: 0.008881082110950978\n",
      "Packet_Length_Std: 0.008788875441301249\n",
      "Fwd_Bwd_Packet_Length_Mean_Product: 0.00869607375334981\n",
      "Packet_Length_Mean: 0.008654069862116455\n",
      "Fwd_Packet_Length_Max: 0.008583547308159368\n",
      "Fwd_Bwd_Packet_Length_Mean_Diff: 0.008518059109324837\n",
      "Packet_Length_Variance: 0.008441233215618078\n",
      "Total_Length_of_Fwd_Packets: 0.008209443436996406\n",
      "Bwd_IAT_Max: 0.008056180530868394\n",
      "Total_Bytes: 0.00802977671001522\n",
      "Avg_Packet_Length: 0.008017101067259435\n",
      "Fwd_Bwd_IAT_Mean_Ratio: 0.007813467742627945\n",
      "Bwd_IAT_Total: 0.007658179111314204\n",
      "Packet_Length_Median: 0.007619968490645348\n",
      "Bwd_IAT_Min: 0.007466154269973594\n",
      "URG_Flag_Count: 0.007379101871986088\n",
      "Avg_Bwd_Segment_Size: 0.007200877203938829\n",
      "Bwd_Header_Length: 0.007123780703544272\n",
      "Bwd_IAT_Mean: 0.007065225334575916\n",
      "Bwd_Packet_Length_Mean: 0.006813940959078177\n",
      "Fwd_Packet_Length_Std: 0.006775153475877418\n",
      "Packet_Length_Range: 0.006764296113799495\n",
      "Max_Packet_Length: 0.006622952167102257\n",
      "Total_Length_of_Bwd_Packets: 0.006525783655478055\n",
      "Subflow_Bwd_Bytes: 0.006314787144203752\n",
      "Fwd_Bwd_IAT_Mean_Product: 0.006076887262435537\n",
      "Min_Packet_Length: 0.00586154879508402\n",
      "Bwd_IAT_Std: 0.005700868882828656\n",
      "Bwd_Packet_Length_Max: 0.005621922714042533\n",
      "Subflow_Fwd_Packets: 0.0055724918952585935\n",
      "Fwd_Packet_Length_Min: 0.005086920389660705\n",
      "Bwd_Packet_Length_Min: 0.00501797431710591\n",
      "Total_Packets: 0.0049457450779115085\n",
      "Total_Fwd_Packets: 0.004809890186914605\n",
      "Bwd_Packet_Length_Std: 0.004611922132647208\n",
      "Subflow_Bwd_Packets: 0.003970369555506465\n",
      "Total_Backward_Packets: 0.0037050687204070254\n",
      "Idle_Mean: 0.0033708293438324093\n",
      "Idle_Max: 0.0033597229253895565\n",
      "Idle_Min: 0.0028302303854013423\n",
      "Active_Mean: 0.0028166343734813224\n",
      "Active_Min: 0.002720433611538876\n",
      "Active_Max: 0.002694854880451297\n",
      "act_data_pkt_fwd: 0.002681496088167456\n",
      "Protocol_1: 0.002384158119035899\n",
      "Protocol_2: 0.001993448938555466\n",
      "Down/Up_Ratio: 0.0017640561642220975\n",
      "FIN_Flag_Count: 0.0013898003637107116\n",
      "ACK_Flag_Count: 0.0013618638815992268\n",
      "Idle_Std: 0.0012050854457858035\n",
      "Fwd_PSH_Flags: 0.0010029584805151758\n",
      "SYN_Flag_Count: 0.0008575858691794492\n",
      "Active_Std: 0.0007304921800176282\n",
      "PSH_Flag_Count: 0.0006604052896282858\n",
      "Protocol_0: 6.655672197546466e-05\n",
      "Bwd_PSH_Flags: 0.0\n",
      "Fwd_URG_Flags: 0.0\n",
      "Bwd_URG_Flags: 0.0\n",
      "RST_Flag_Count: 0.0\n",
      "CWE_Flag_Count: 0.0\n",
      "ECE_Flag_Count: 0.0\n",
      "Fwd_Avg_Bytes/Bulk: 0.0\n",
      "Fwd_Avg_Packets/Bulk: 0.0\n",
      "Fwd_Avg_Bulk_Rate: 0.0\n",
      "Bwd_Avg_Bytes/Bulk: 0.0\n",
      "Bwd_Avg_Packets/Bulk: 0.0\n",
      "Bwd_Avg_Bulk_Rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Pair feature names with their importances\n",
    "feature_importance_pairs = list(zip(X.columns, rf_importances))\n",
    "\n",
    "# Sort the feature importance pairs by importance (descending order)\n",
    "sorted_feature_importance_pairs = sorted(feature_importance_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted feature importance pairs\n",
    "print(\"Feature importances (Random Forest):\")\n",
    "for feature, importance in sorted_feature_importance_pairs:\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'Source_Port',\n",
    "    'Flow_Duration',\n",
    "    'Flow_IAT_Max',\n",
    "    'Flow_IAT_Min',\n",
    "    'Flow_IAT_Mean',\n",
    "    'Init_Win_bytes_forward',\n",
    "    'Fwd_Packets/s',\n",
    "    'Flow_Packets/s',\n",
    "    'Fwd_IAT_Min',\n",
    "    'Fwd_IAT_Mean',\n",
    "    'Fwd_IAT_Max',\n",
    "    'Total_IAT',\n",
    "    'Fwd_IAT_Total',\n",
    "    'Destination_Port',\n",
    "    'Bwd_Packets/s',\n",
    "    'Init_Win_bytes_backward',\n",
    "    'Total_Header_Length',\n",
    "    'Flow_Bytes/s',\n",
    "    'Fwd_IAT_Std',\n",
    "    'Fwd_Bwd_Header_Length_Ratio',\n",
    "    'Fwd_Header_Length',\n",
    "    'Fwd_Bwd_Packets_per_s_Ratio',\n",
    "    'min_seg_size_forward',\n",
    "    'Avg_Fwd_Segment_Size',\n",
    "    'Flow_Bytes_Packets_per_s_Ratio',\n",
    "    'Average_Packet_Size',\n",
    "    'Fwd_Bwd_Packet_Length_Mean_Ratio',\n",
    "    'Fwd_Packet_Length_Mean',\n",
    "    'Avg_Fwd_Bwd_Segment_Size_Ratio',\n",
    "    'Subflow_Fwd_Bytes',\n",
    "    'Packet_Length_Std',\n",
    "    'Fwd_Bwd_Packet_Length_Mean_Product',\n",
    "    'Packet_Length_Mean'\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with selected features\n",
    "selected_X = X[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.6310\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61       591\n",
      "           1       0.57      0.58      0.57       354\n",
      "           2       0.65      0.63      0.64       800\n",
      "           3       0.71      0.67      0.69       529\n",
      "\n",
      "    accuracy                           0.63      2274\n",
      "   macro avg       0.63      0.63      0.63      2274\n",
      "weighted avg       0.63      0.63      0.63      2274\n",
      "\n",
      "XGB Classifier Accuracy: 0.7476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70       591\n",
      "           1       0.79      0.67      0.72       354\n",
      "           2       0.73      0.76      0.75       800\n",
      "           3       0.79      0.83      0.81       529\n",
      "\n",
      "    accuracy                           0.75      2274\n",
      "   macro avg       0.76      0.74      0.75      2274\n",
      "weighted avg       0.75      0.75      0.75      2274\n",
      "\n",
      "KNN Accuracy: 0.5031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.54      0.49       591\n",
      "           1       0.41      0.39      0.40       354\n",
      "           2       0.56      0.53      0.54       800\n",
      "           3       0.55      0.50      0.52       529\n",
      "\n",
      "    accuracy                           0.50      2274\n",
      "   macro avg       0.49      0.49      0.49      2274\n",
      "weighted avg       0.51      0.50      0.50      2274\n",
      "\n",
      "Neural Network Accuracy: 0.3175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.28      0.32       591\n",
      "           1       0.22      0.40      0.29       354\n",
      "           2       0.39      0.14      0.20       800\n",
      "           3       0.34      0.57      0.43       529\n",
      "\n",
      "    accuracy                           0.32      2274\n",
      "   macro avg       0.33      0.35      0.31      2274\n",
      "weighted avg       0.34      0.32      0.30      2274\n",
      "\n",
      "Naive Bayes Accuracy: 0.2401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.12      0.18       591\n",
      "           1       0.18      0.75      0.29       354\n",
      "           2       0.37      0.21      0.27       800\n",
      "           3       0.32      0.08      0.12       529\n",
      "\n",
      "    accuracy                           0.24      2274\n",
      "   macro avg       0.30      0.29      0.21      2274\n",
      "weighted avg       0.32      0.24      0.21      2274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a list of classifiers\n",
    "classifiers = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n",
    "    (\"XGB Classifier\", XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=42)),\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"Neural Network\", MLPClassifier(max_iter=500, random_state=42)),\n",
    "    (\"Naive Bayes\", GaussianNB())\n",
    "]\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\anaconda3\\lib\\site-packages\\distributed\\config.py:63: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config.update(yaml.load(text) or {})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.6689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64       591\n",
      "           1       0.68      0.56      0.61       354\n",
      "           2       0.68      0.68      0.68       800\n",
      "           3       0.70      0.74      0.72       529\n",
      "\n",
      "    accuracy                           0.67      2274\n",
      "   macro avg       0.67      0.66      0.66      2274\n",
      "weighted avg       0.67      0.67      0.67      2274\n",
      "\n",
      "Gradient Boosting Accuracy: 0.6288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.57       591\n",
      "           1       0.71      0.47      0.57       354\n",
      "           2       0.62      0.67      0.65       800\n",
      "           3       0.63      0.77      0.69       529\n",
      "\n",
      "    accuracy                           0.63      2274\n",
      "   macro avg       0.64      0.61      0.62      2274\n",
      "weighted avg       0.63      0.63      0.62      2274\n",
      "\n",
      "AdaBoost Accuracy: 0.4916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.43      0.45       591\n",
      "           1       0.44      0.27      0.34       354\n",
      "           2       0.50      0.49      0.49       800\n",
      "           3       0.51      0.70      0.59       529\n",
      "\n",
      "    accuracy                           0.49      2274\n",
      "   macro avg       0.48      0.48      0.47      2274\n",
      "weighted avg       0.49      0.49      0.48      2274\n",
      "\n",
      "CatBoost Accuracy: 0.7076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       591\n",
      "           1       0.76      0.60      0.67       354\n",
      "           2       0.70      0.74      0.72       800\n",
      "           3       0.73      0.78      0.76       529\n",
      "\n",
      "    accuracy                           0.71      2274\n",
      "   macro avg       0.72      0.70      0.70      2274\n",
      "weighted avg       0.71      0.71      0.71      2274\n",
      "\n",
      "LightGBM Accuracy: 0.7221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.68       591\n",
      "           1       0.78      0.62      0.69       354\n",
      "           2       0.71      0.73      0.72       800\n",
      "           3       0.76      0.82      0.79       529\n",
      "\n",
      "    accuracy                           0.72      2274\n",
      "   macro avg       0.73      0.71      0.72      2274\n",
      "weighted avg       0.72      0.72      0.72      2274\n",
      "\n",
      "SVM Accuracy: 0.3940\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.08      0.15       591\n",
      "           1       0.77      0.03      0.05       354\n",
      "           2       0.38      0.75      0.51       800\n",
      "           3       0.39      0.45      0.42       529\n",
      "\n",
      "    accuracy                           0.39      2274\n",
      "   macro avg       0.52      0.33      0.28      2274\n",
      "weighted avg       0.48      0.39      0.32      2274\n",
      "\n",
      "Logistic Regression Accuracy: 0.3989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.14      0.22       591\n",
      "           1       1.00      0.02      0.03       354\n",
      "           2       0.40      0.73      0.51       800\n",
      "           3       0.36      0.45      0.40       529\n",
      "\n",
      "    accuracy                           0.40      2274\n",
      "   macro avg       0.58      0.33      0.29      2274\n",
      "weighted avg       0.53      0.40      0.34      2274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a list of classifiers\n",
    "classifiers = [\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42)),\n",
    "    (\"AdaBoost\", AdaBoostClassifier(random_state=42)),\n",
    "    (\"CatBoost\", CatBoostClassifier(verbose=0, random_state=42)),\n",
    "    (\"LightGBM\", lgb.LGBMClassifier(random_state=42)),\n",
    "    (\"SVM\", SVC(random_state=42)),\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "]\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
